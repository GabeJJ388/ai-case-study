# ai-case-study

# Anthropic, Safe AI for Everyone

## Overview and Origin

* ### Anthropic PBC and it's humble beginnings.

* According to Time's 100 Most Influential Companies of 2024, the Co-Founder and CEO of Athropic, Dario Amodei was set to launch the first open source AI for public use in 2022, only 2 years after the company's creation.

* Siblings Dario Amodei and Daniela Amodei co-founded Anthropic after starting on the research and development board of OpenAI, creator company of chat GPT **(Builtin.com)**.

* "Anthropic's founders along with five other colleagues, left OpenAI in 2020 due to concerns over OpenAI's lack of commitment to safety." **(BuiltIn.com)**. Instead of rushing the development of a neuro learning open source AI, Anthropic delayed their release of their AI chatbot _Claude_ until they were fully confident in its processing and guideline capabilities (using what they have coined as a constitution of 40 or so prerequisite processing requirements).

* The CEO Dario Amodei believes the decision to delay release must have cost the company billions of dollars, but he believes it was the right thing to do. Already since 'Claude' was released they have made 7 billion from public investors by May 2024 and expanded from 50 to 500 employees and have since lauched 3 generations of _Claude_. **(Time.com)**

## Business Activities

* The goal of Anthropic was to avoid a race to the top that could be irresponsible and dangerous to the development of human society and perhaps technological evolution. As Amodei was quoted saying in Time.com:
* >“We’re not trying to say we’re the good guys and the others are the bad guys,” Amodei says. “We’re trying to pull the ecosystem in a direction where everyone can be the good guy.”

* The market share of _Claude_ is only at 0.13% compared to Chat GPT's 17.5%. But this does not speak for the quality of the platform, the answers by _Claude_ vs. ChatGPT are easier to digest, give many more warnings on AI assumed information, give plenty of warnings and cautions on facts vs. newly generated neuro processes **(6sense.com)**. ChatGPT will allow very morally disturbing questions to be answered for examples questions how to manipulate other people psychologically, or even advice on types of torture. _Claude_ has safeguards against those morally questionable inquiries.

* The Solution to those morally confounding facets of the human psyche, usually tested by young adults and even kids, and rarely the mentally perturbed, is what Anthropic calls the constitution. Not only do these 50 or so rules put in place in anthropic not confound each other, but their are some given priority to others, then tested for two years and finally implemented. The full constitution is even available for the public to review or scrutinize on anthropics website. **(anthropic.com)**. Anthropic explains the risks of unregulated AI as such: "First, it may require people to interact with disturbing outputs. Second, it does not scale efficiently. As the number of responses increases or the models produce more complex responses, crowdworkers will find it difficult to keep up with or fully understand them. Third, reviewing even a subset of outputs requires substantial time and resources, making this process inaccessible for many researchers." **(Anthropic.com)**.

* Anthropic describes it's solution to the problem as follows: "Constitutional AI responds to these shortcomings by using AI feedback to evaluate outputs. The system uses a set of principles to make judgments about outputs, hence the term “Constitutional.” At a high level, the constitution guides the model to take on the normative behavior described in the constitution – here, helping to avoid toxic or discriminatory outputs, avoiding helping a human engage in illegal or unethical activities, and broadly creating an AI system that is helpful, honest, and harmless." **(Anthropic.com)**. The constitution is a growing heart for _Claude_'s extremely developed AI Neuro processes or for lack of better metaphor, brain. _Claude_ would be a great alternative for lower level school use, higher learning scholarly use, professional use, etc. They were will be no way of eradicating other open source AI's, but this may well be a way to balance the race to the top movement with more responsible growth trends.

## Landscape

* Anthropic is in the Open Source Chatbot Industry of AI. The most prevalently industry using AI at the time.

* The biggest trends in this field are hands down ChatGPT and Gemini, both have been released in the last two years. Anthropic was ahead in release date by 3 months to OpenAI's ChatGPT and chose to delay to finish working the validity of their constitution **(Time.com)**.

* There are 30 or so released ChatBot's ranging in popularity at this time, the most popular five seem to be: ChatGPT, Claude, Meta AI, Google Gemini, and Microsoft Copilot. **(Zapier.com)**.

## Results

* It is too soon to see the impact of this AI platform and development but the founders and the investors of this company are fully confident that the implications of a balance in the development of higher level artificial intelligence and a pull away from the race to the top will insure safe growth in the use and development of AI in the future.

* The core metrics that Anthropic prides itself on achieving are quality (of Articficial Analysis) of answers, speed, and price ([artificialanalysis.ai](https://artificialanalysis.ai/providers/anthropic)). The quality price and speed have all increased incrementally between the third iteration and 4 iteration (3.5), in quality it has gone from 70 to 77 rating in Artificial Analysis, in speed it has gone from a 28 to 62 rating, and in price it has gone from a 30 down to 6 which is improvement for the public/buyers (artificialanalysis.ai).

    * On Vellum.ai an AI comparison site, Sonnet 3.5 (Anthropic's most recent release) scored slightly higher than ChatGPT4, and is the only viable compition so far. 

    ** Accuracy Comparison: Claude 3.5 Sonnet (0.72) does better than GPT-4o (0.65), but GPT-4 has the highest mean absolute score (0.77) when it comes to accuracy.
    ** Regressions: Despite the overall better performance, Claude 3.5 Sonnet has 5 specific cases where it performs worse than GPT-4o, showing that the model introduced issues in certain areas. However, there are not very significant.
    ** Improvements: We do see that Claude 3.5 Sonnet shows 12 improvements compared to GPT-4o, which signals that more improvements were achieved than regressions. More research and working with the prompt is needed here to eliminate the regressions but maintain these           improvements. GPT-4 however had the most improvements when compared to GPT-4o.

## Recommendations

* Anthropic is the superior product, has the better engineering, is showing more responsible at long term growth, but there is one area they fail greatly at, and that's marketing and design. Their AI is the most advanced in the world right now and their app and website looks like it was designed by toddlers. They are missing out on major growth accomplishments. They have made it safer, but the optics look boring. Safe does not need to be boring. Roller coasters are safe, and yet not boring. I strongly suggest they get an aesthetics and web design team to help with their branding. This is new age stuff, and I feel like I'm using a beta of yahoo answers when I use their app. 

* Trully a beauty going to waste. It would not take much to revamp and remarket. I hope this is something they attempt in the near future or they will lose the race to balance that they were so hoping for.

* As mentioned before schools of all ranges could use this software, as well as it being the main AI used in professional settings. Their branding could be done to reflect something of the sort. Nothing intimidating but something as fresh as the chrome logo would be instrumental in cementing their place in high AI social settings.

* What I am suggesting does not take much more research, designing, and testing as they have already done. But the fact that they are at .13% compared to ChatGPT's 17.5% market prevalence is sad, and not a testimony of the work they have done at Anthropic or the potential the company and product have. I believe the solution to be a marketing faux pas that can be easily corrected. Once done corretly, the hard work happening at Anthropic will surely be appreciated. I can't wait to see the development of this intelligence race.
